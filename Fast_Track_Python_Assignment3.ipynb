{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3d618d",
   "metadata": {},
   "source": [
    "# What is the process for loading a dataset from an external source?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279b2b5",
   "metadata": {},
   "source": [
    "Steps to Import a CSV File into Python using Pandas:-\n",
    "Step 1: Capture the File Path.\n",
    "C:\\Users\\Ron\\Desktop\\Clients.csv\n",
    "Step 2: Apply the Python code\n",
    "import pandas as pd\n",
    "df = pd.read_csv (r'C:\\Users\\Ron\\Desktop\\Clients.csv')  \n",
    "print (df)\n",
    "Step 3: Run the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d809325",
   "metadata": {},
   "source": [
    "# How can we use pandas to read JSON files?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9bae57",
   "metadata": {},
   "source": [
    "To read the files, we use read_json() function and through it, we pass the path to the JSON file we want to read. Once we do that, it returns a “DataFrame”( A table of rows and columns) that stores data. If we want to read a file that is located on remote servers then we pass the link to its location instead of a local path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984d342",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_json(\"FILE_JSON.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4311f",
   "metadata": {},
   "source": [
    "# Describe the significance of DASK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382564ee",
   "metadata": {},
   "source": [
    "Dask is a flexible library for parallel computing in Python.\n",
    "\n",
    "Dask is composed of two parts:\n",
    "\n",
    "Dynamic task scheduling optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.\n",
    "\n",
    "“Big Data” collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of dynamic task schedulers.\n",
    "\n",
    "Dask emphasizes the following virtues:\n",
    "\n",
    "Familiar: Provides parallelized NumPy array and Pandas DataFrame objects\n",
    "\n",
    "Flexible: Provides a task scheduling interface for more custom workloads and integration with other projects.\n",
    "\n",
    "Native: Enables distributed computing in pure Python with access to the PyData stack.\n",
    "\n",
    "Fast: Operates with low overhead, low latency, and minimal serialization necessary for fast numerical algorithms\n",
    "\n",
    "Scales up: Runs resiliently on clusters with 1000s of cores\n",
    "\n",
    "Scales down: Trivial to set up and run on a laptop in a single process\n",
    "\n",
    "Responsive: Designed with interactive computing in mind, it provides rapid feedback and diagnostics to aid humans\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c360002",
   "metadata": {},
   "source": [
    "# Describe the functions of DASK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75da1fd",
   "metadata": {},
   "source": [
    "Familiar: Provides parallelized NumPy array and Pandas DataFrame objects\n",
    "\n",
    "Flexible: Provides a task scheduling interface for more custom workloads and integration with other projects.\n",
    "\n",
    "Native: Enables distributed computing in pure Python with access to the PyData stack.\n",
    "\n",
    "Fast: Operates with low overhead, low latency, and minimal serialization necessary for fast numerical algorithms\n",
    "\n",
    "Scales up: Runs resiliently on clusters with 1000s of cores\n",
    "\n",
    "Scales down: Trivial to set up and run on a laptop in a single process\n",
    "\n",
    "Responsive: Designed with interactive computing in mind, it provides rapid feedback and diagnostics to aid humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc74d2c",
   "metadata": {},
   "source": [
    "# Describe Cassandra's features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afec7c6",
   "metadata": {},
   "source": [
    "Apache Cassandra is an open source, user-available, distributed, NoSQL DBMS which is designed to handle large amounts of data across many servers. It provides zero point of failure. Cassandra offers massive support for clusters spanning multiple datacentres. \n",
    "\n",
    "There are some massive features of Cassandra. Here are some of the features described below: \n",
    "\n",
    "1.Distributed: \n",
    "Each node in the cluster has has same role. There’s no question of failure & the data set is distributed across the cluster but one issue is there that is the master isn’t present in each node to support request for service.\n",
    "\n",
    "2.Supports replication & Multi data center replication: \n",
    "Replication factor comes with best configurations in cassandra. Cassandra is designed to have a distributed system, for the deployment of large number of nodes for across multiple data centers and other key features too.\n",
    "\n",
    "3.Scalability: \n",
    "It is designed to r/w throughput, Increase gradually as new machines are added without interrupting other applications.\n",
    "\n",
    "4.Fault-tolerance: \n",
    "Data is automatically stored & replicated for fault-tolerance. If a node Fails, then it is replaced within no time.\n",
    "\n",
    "5.MapReduce Support: \n",
    "It supports Hadoop integration with MapReduce support.Apache Hive & Apache Pig is also supported.\n",
    "\n",
    "6.Query Language: \n",
    "Cassandra has introduced the CQL (Cassandra Query Language). Its a simple interface for accessing the Cassandra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
